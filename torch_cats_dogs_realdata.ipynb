{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "from PIL import Image \n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='C:\\\\Users\\\\Sushanth\\\\Downloads\\\\CATS_DOGS\\\\'\n",
    "with Image.open(dataDir+'test\\\\'+'CAT\\\\10107.jpg') as Im:\n",
    "    display(Im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names=[]\n",
    "for folder,subfolder,fnames in os.walk(dataDir):\n",
    "    for img in fnames:\n",
    "        img_names.append(folder+'\\\\'+img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sizes=[]\n",
    "rejected=[]\n",
    "for im_name in img_names:\n",
    "    try:\n",
    "        with Image.open(im_name) as img:\n",
    "            img_sizes.append(img.size)\n",
    "    except:\n",
    "        rejected.append(im_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(img_sizes)\n",
    "df[0].describe()\n",
    "df[1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=Image.open(dataDir+'train\\\\Dog\\\\'+'14.jpg')\n",
    "display(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform=torchvision.transforms.Compose([torchvision.transforms.RandomRotation(10),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.Resize(224),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
    "\n",
    "test_transform=torchvision.transforms.Compose([torchvision.transforms.Resize(224),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root='C:\\\\Users\\\\Sushanth\\\\Downloads\\\\CATS_DOGS\\\\'\n",
    "train_data=torchvision.datasets.ImageFolder(os.path.join(root,'train'),transform=train_transform)\n",
    "test_data=torchvision.datasets.ImageFolder(os.path.join(root,'test'),transform=test_transform)\n",
    "torch.manual_seed(101)\n",
    "train_loader=torch.utils.data.DataLoader(train_data,batch_size=64,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_data,batch_size=64)\n",
    "class_names=train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs,labels in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Im=torchvision.utils.make_grid(imgs,nrow=5)\n",
    "inv_normalize=torchvision.transforms.Normalize([-0.485/0.229,-0.456/0.229,-0.406/0.229],[1/0.229,1/0.224,1/0.225])\n",
    "im_inv=inv_normalize(Im)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(np.transpose(im_inv.numpy(),[1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convnet_cat_dog(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convnet_cat_dog,self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,6,3,1)\n",
    "        self.conv2=nn.Conv2d(6,16,3,1)\n",
    "        self.conv3=nn.Conv2d(16,32,3,1)\n",
    "        self.conv4=nn.Conv2d(32,64,3,1)\n",
    "        self.fc1=nn.Linear(64*12*12,2048)\n",
    "        self.fc2=nn.Linear(2048,512)\n",
    "        self.fc3=nn.Linear(512,64)\n",
    "        self.fc4=nn.Linear(64,16)\n",
    "        self.fc5=nn.Linear(16,2)\n",
    "    def forward(self,X):\n",
    "        C1=F.relu(self.conv1(X))\n",
    "        p1=F.max_pool2d(C1,(2,2))\n",
    "        C2=F.relu(self.conv2(p1))\n",
    "        p2=F.max_pool2d(C2,(2,2))\n",
    "        C3=F.relu(self.conv3(p2))\n",
    "        p3=F.max_pool2d(C3,(2,2))\n",
    "        C4=F.relu(self.conv4(p3))\n",
    "        p4=F.max_pool2d(C4,(2,2))\n",
    "        p4f=p4.view(-1,64*12*12)\n",
    "        fc1_op=F.relu(self.fc1(p4f))\n",
    "        fc2_op=F.relu(self.fc2(fc1_op))\n",
    "        fc3_op=F.relu(self.fc3(fc2_op))\n",
    "        fc4_op=F.relu(self.fc4(fc3_op))\n",
    "        fc5_op=self.fc5(fc4_op)\n",
    "        return(fc5_op)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model=convnet_cat_dog()\n",
    "crit=nn.CrossEntropyLoss()\n",
    "opt=torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________Epoch: 0_________________________________\n",
      "Batch:0 Loss:0.6944\n",
      "Batch:30 Loss:0.6903\n",
      "Batch:60 Loss:0.6923\n",
      "Batch:90 Loss:0.6908\n",
      "Batch:120 Loss:0.6694\n",
      "Batch:150 Loss:0.6316\n",
      "Batch:180 Loss:0.5990\n",
      "Batch:210 Loss:0.5716\n",
      "Batch:240 Loss:0.5856\n",
      "Batch:270 Loss:0.6389\n",
      "__________________Epoch: 1_________________________________\n",
      "Batch:0 Loss:0.5296\n",
      "Batch:30 Loss:0.5208\n",
      "Batch:60 Loss:0.6304\n",
      "Batch:90 Loss:0.5152\n",
      "Batch:120 Loss:0.5277\n",
      "Batch:150 Loss:0.5496\n",
      "Batch:180 Loss:0.4783\n",
      "Batch:210 Loss:0.5522\n",
      "Batch:240 Loss:0.5959\n",
      "Batch:270 Loss:0.4726\n",
      "__________________Epoch: 2_________________________________\n",
      "Batch:0 Loss:0.4647\n",
      "Batch:30 Loss:0.5158\n",
      "Batch:60 Loss:0.4506\n",
      "Batch:90 Loss:0.4808\n",
      "Batch:120 Loss:0.4358\n",
      "Batch:150 Loss:0.4363\n",
      "Batch:180 Loss:0.5585\n",
      "Batch:210 Loss:0.5022\n",
      "Batch:240 Loss:0.4202\n",
      "Batch:270 Loss:0.4935\n",
      "__________________Epoch: 3_________________________________\n",
      "Batch:0 Loss:0.4437\n",
      "Batch:30 Loss:0.4644\n",
      "Batch:60 Loss:0.5619\n",
      "Batch:90 Loss:0.5400\n",
      "Batch:120 Loss:0.3637\n",
      "Batch:150 Loss:0.4027\n",
      "Batch:180 Loss:0.3249\n",
      "Batch:210 Loss:0.4756\n",
      "Batch:240 Loss:0.3689\n",
      "Batch:270 Loss:0.4792\n",
      "__________________Epoch: 4_________________________________\n",
      "Batch:0 Loss:0.4394\n",
      "Batch:30 Loss:0.3819\n",
      "Batch:60 Loss:0.3771\n",
      "Batch:90 Loss:0.3475\n",
      "Batch:120 Loss:0.3447\n",
      "Batch:150 Loss:0.3867\n",
      "Batch:180 Loss:0.3201\n",
      "Batch:210 Loss:0.3480\n",
      "Batch:240 Loss:0.3310\n",
      "Batch:270 Loss:0.2849\n",
      "__________________Epoch: 5_________________________________\n",
      "Batch:0 Loss:0.3999\n",
      "Batch:30 Loss:0.6085\n",
      "Batch:60 Loss:0.3286\n",
      "Batch:90 Loss:0.3055\n",
      "Batch:120 Loss:0.3878\n",
      "Batch:150 Loss:0.4463\n",
      "Batch:180 Loss:0.3559\n",
      "Batch:210 Loss:0.2998\n",
      "Batch:240 Loss:0.3022\n",
      "Batch:270 Loss:0.3690\n",
      "__________________Epoch: 6_________________________________\n",
      "Batch:0 Loss:0.3294\n",
      "Batch:30 Loss:0.3198\n",
      "Batch:60 Loss:0.2512\n",
      "Batch:90 Loss:0.3952\n",
      "Batch:120 Loss:0.2481\n",
      "Batch:150 Loss:0.4122\n",
      "Batch:180 Loss:0.5335\n",
      "Batch:210 Loss:0.3030\n",
      "Batch:240 Loss:0.2370\n",
      "Batch:270 Loss:0.2822\n",
      "__________________Epoch: 7_________________________________\n",
      "Batch:0 Loss:0.3161\n",
      "Batch:30 Loss:0.2704\n",
      "Batch:60 Loss:0.2847\n",
      "Batch:90 Loss:0.3697\n",
      "Batch:120 Loss:0.2883\n",
      "Batch:150 Loss:0.2896\n",
      "Batch:180 Loss:0.4224\n",
      "Batch:210 Loss:0.3469\n",
      "Batch:240 Loss:0.2698\n",
      "Batch:270 Loss:0.2462\n",
      "__________________Epoch: 8_________________________________\n",
      "Batch:0 Loss:0.2965\n",
      "Batch:30 Loss:0.3425\n",
      "Batch:60 Loss:0.2651\n",
      "Batch:90 Loss:0.3136\n",
      "Batch:120 Loss:0.2970\n",
      "Batch:150 Loss:0.2133\n",
      "Batch:180 Loss:0.3048\n",
      "Batch:210 Loss:0.2760\n",
      "Batch:240 Loss:0.2394\n",
      "Batch:270 Loss:0.2669\n",
      "__________________Epoch: 9_________________________________\n",
      "Batch:0 Loss:0.1954\n",
      "Batch:30 Loss:0.2490\n",
      "Batch:60 Loss:0.2537\n",
      "Batch:90 Loss:0.2371\n",
      "Batch:120 Loss:0.2976\n",
      "Batch:150 Loss:0.3040\n",
      "Batch:180 Loss:0.3369\n",
      "Batch:210 Loss:0.1924\n",
      "Batch:240 Loss:0.2284\n",
      "Batch:270 Loss:0.1608\n"
     ]
    }
   ],
   "source": [
    "def train_single_epoch(d_loader,mod,crit,opt,disp_int=30):\n",
    "    running_batch_loss=np.zeros([len(d_loader),1])\n",
    "    for batch,ex in enumerate(d_loader):\n",
    "        opt.zero_grad()\n",
    "        preds=mod.forward(ex[0])\n",
    "        loss=crit(preds,ex[1])\n",
    "        running_batch_loss[batch]=loss.item()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if(batch%disp_int==0):\n",
    "            print(f'Batch:{batch} Loss:{loss.item():0.4f}')\n",
    "    return(mod,running_batch_loss)\n",
    "def train_model(epochs,d_loader,mod,crit,opt,disp_int=30):\n",
    "    running_epoch_loss=[]\n",
    "    for i in range(epochs):\n",
    "        print(f'__________________Epoch: {i}_________________________________')\n",
    "        mod,running_batch_loss=train_single_epoch(d_loader,mod,crit,opt,disp_int=disp_int)\n",
    "        running_epoch_loss.extend(running_batch_loss)\n",
    "    return(mod,running_epoch_loss)\n",
    "\n",
    "epochs=10\n",
    "mod,running_epoch_loss=train_model(epochs,train_loader,model,crit,opt,disp_int=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(mod,d_loader):\n",
    "    pred_probs=[]\n",
    "    pred_labels=[]\n",
    "    true_labels=[]\n",
    "    for b,ex in enumerate(d_loader):\n",
    "        preds=mod.forward(ex[0])\n",
    "        prob=torch.softmax(preds,1)\n",
    "        probs=np.max(prob.detach().numpy(),axis=1)\n",
    "        labs=np.argmax(prob.detach().numpy(),axis=1)\n",
    "        pred_probs.extend(probs)\n",
    "        pred_labels.extend(labs)\n",
    "        true_labels.extend(ex[1].detach().numpy())\n",
    "    return(pred_probs,pred_labels,true_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_mat(pred_labels,true_labels,num_classes,disp_flag=0):\n",
    "    cm=np.zeros([num_classes,num_classes])\n",
    "    k=0\n",
    "    for k in range(len(pred_labels)):\n",
    "        cm[pred_labels[k],true_labels[k]]+=1\n",
    "        k+=1\n",
    "    if(disp_flag==1):\n",
    "        print(cm)\n",
    "    return(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_train,pred_labels_train,true_labels_train=eval_model(mod,train_loader)\n",
    "pred_probs_test,pred_labels_test,true_labels_test=eval_model(mod,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train=get_conf_mat(pred_labels_train,true_labels_train,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test=get_conf_mat(pred_labels_test,true_labels_test,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9063650429493678"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.diag(cm_train))/np.sum(cm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8597024476083827"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.diag(cm_test))/np.sum(cm_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv_torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6f6d812eb8ff2e31293d170cddd5c8e045640f5f98450a4a81ed1895a3a33d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
